{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd21e6b",
   "metadata": {},
   "source": [
    "# The dataset\n",
    "1. The dataset has three splits:\n",
    "    + train\n",
    "    + test\n",
    "    + unsupervised\n",
    "   Splits can be found in the hugging faces page of the dataset.\n",
    "   Or with the function get_dataset_split_names(\"name_of_dataset\")\n",
    "2. Here are the size of datasets:\n",
    "    + Size of the train dataset: 25000\n",
    "    + Size of the test dataset: 25000\n",
    "    + Size of the unsupervised dataset: 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from datasets import load_dataset_builder\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817b69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset_builder(\"imdb\")\n",
    "dataset_train = load_dataset(\"imdb\", split='train')\n",
    "dataset_test = load_dataset(\"imdb\", split='test')\n",
    "dataset_unsupervised = load_dataset(\"imdb\", split='unsupervised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8587f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ac115",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of the train dataset: \" + str(len(dataset_train)))\n",
    "print(\"Size of the test dataset: \" + str(len(dataset_test)))\n",
    "print(\"Size of the unsupervised dataset: \" + str(len(dataset_unsupervised)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1eabb",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier\n",
    "\n",
    "## I. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5dd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_filter = ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+',\n",
    "                      ',', '.', '/', ':', ';', '<', '=', '>', '?', '@',\n",
    "                      '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n",
    "\n",
    "def to_lower_case(row: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Lower text field in the row dict\n",
    "    return: updated row\n",
    "    \"\"\"\n",
    "    row['text'] = row['text'].lower()\n",
    "    return row\n",
    "\n",
    "def remove_punctuation(row: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Replace punctuation from punctuation_filter list to\n",
    "    spaces in the text field of row dict\n",
    "    return: updated row\n",
    "    \"\"\"\n",
    "    for punctuation in punctuation_filter:\n",
    "        row['text'] = row['text'].replace(punctuation, ' ')\n",
    "    return row\n",
    "\n",
    "def preprocessing(row: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Lower text field in the row dict and replace punctuation\n",
    "    from punctuation_filter list to spaces in the text field\n",
    "    of row dict\n",
    "    return: updated row\n",
    "    \"\"\"\n",
    "    return to_lower_case(remove_punctuation(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_train = dataset_test.map(preprocessing)\n",
    "preprocess_test = dataset_train.map(preprocessing)\n",
    "preprocess_unsupervised = dataset_unsupervised.map(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f7d29",
   "metadata": {},
   "source": [
    "## II. Naive Bayes classifier\n",
    "\n",
    "### Our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(documents: Dataset, classes: list):\n",
    "    logprior = {}\n",
    "    loglikelihood = {k: {} for k in classes}\n",
    "    \n",
    "    # Vocabulary of documents\n",
    "    voc = {} # Histogram {word: count}\n",
    "    class_voc = {k: {} for k in classes}\n",
    "    total_count = 0\n",
    "    \n",
    "    def update_voc(document: Dataset) -> None:\n",
    "        if isinstance(document['text'], str):\n",
    "            words = document['text'].split()\n",
    "        else:\n",
    "            words = document['text']    \n",
    "        nonlocal total_count\n",
    "        total_count += len(words)\n",
    "        for word in words:\n",
    "            voc.update({word: voc.get(word, 0) + 1})\n",
    "            c = document['label']\n",
    "            class_voc[c].update({word: class_voc[c].get(word, 0) + 1})\n",
    "    \n",
    "    documents.map(update_voc)\n",
    "\n",
    "    # Update total count for loglikelihood formula\n",
    "    total_count += len(voc)\n",
    "\n",
    "    for c in classes:\n",
    "        num_doc = len(documents)\n",
    "        c_docs = documents.filter(lambda doc: doc['label'] == c)\n",
    "        num_c = len(c_docs)\n",
    "        logprior[c] = math.log(num_c / num_doc)\n",
    "\n",
    "        for word in voc.keys():\n",
    "            loglikelihood[c][word] = math.log((class_voc[c].get(word, 0) + 1)/total_count)\n",
    "        \n",
    "    return logprior, loglikelihood, voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c315d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(test_str: str, logprior: dict, loglikelihood: dict, classes: list, voc: dict) -> int:\n",
    "    sum_max = None\n",
    "    c_max = None\n",
    "    for c in classes:\n",
    "        sum_c = logprior[c]\n",
    "        for word in test_str.split():\n",
    "            if word in voc:\n",
    "                sum_c += loglikelihood[c][word]\n",
    "        if not sum_max or sum_max < sum_c:\n",
    "            sum_max = sum_c\n",
    "            c_max = c\n",
    "    return c_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a830b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1]\n",
    "logprior, loglikelihood, voc = train_naive_bayes(preprocess_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preprocess_test: Dataset, logprior: dict, loglikelihood: dict, classes: list, voc: dict):\n",
    "    confusion = [0, 0, 0, 0] # TP, TN, FP, FN\n",
    "    accuracy=0\n",
    "    def update_voc(document: Dataset) -> None:\n",
    "        nonlocal accuracy\n",
    "        if isinstance(document['text'], str):\n",
    "            comment = document['text']\n",
    "        else:\n",
    "            comment = \" \".join(document['text'])\n",
    "        res = test_naive_bayes(comment, logprior, loglikelihood, classes, voc)\n",
    "        confusion[1-res + (2 * (1-document['label']))] += 1\n",
    "        accuracy += res == document['label']\n",
    "    preprocess_test.map(update_voc)\n",
    "    accuracy = accuracy/len(preprocess_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our implementation accuracy:', accuracy(preprocess_test, logprior, loglikelihood, classes, voc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648bc288",
   "metadata": {},
   "source": [
    "### Scikit\n",
    "#### 3. Implement a naive Bayes classifier using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf376a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\", \n",
    "                             lowercase=True, \n",
    "                             tokenizer = None, \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None, \n",
    "                             max_features = 5000)\n",
    "db = preprocess_train\n",
    "y = db['label']\n",
    "corpus = db['text']\n",
    "bag_of_words = vectorizer.fit_transform(corpus)\n",
    "print(bag_of_words.shape)\n",
    "X = bag_of_words.toarray()\n",
    "\n",
    "clf = MultinomialNB(force_alpha=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer.get_feature_names_out()\n",
    "#print ((clf.feature_log_prob_))\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "#print(vocabulary)\n",
    "vectorizer.transform(['love in my ass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd79586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.predict(vectorizer.transform(['I love this movie'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = preprocess_test['label']\n",
    "X = vectorizer.transform(preprocess_test['text'])\n",
    "score = clf.score(X, y)\n",
    "print('Scikit learn accuracy:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896bda9f",
   "metadata": {},
   "source": [
    "#### 4. Report the accuracy on both training and test set, for both your implementation and the scikit-learn one.\n",
    "- Our implementation accuracy: 0.82152\n",
    "- Scikit learn accuracy: 0.83076\n",
    "\n",
    "\n",
    "#### 5. Most likely, the scikit-learn implementation will give better results. Looking at the documentation, explain why it could be the case.\n",
    "Scikit give results that are 1% better, which might be due to being a libarary. In general, libraries are well optimized.\n",
    "\n",
    "#### 6. Why is accuracy a sufficient measure of evaluation here?\n",
    "Accuracy is \n",
    "\n",
    "\n",
    "#### 7. Using one of the implementation, take at least 2 wrongly classified example from the test set and try explaining why the model failed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17928539",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620cd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda024bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# loading the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(row: dict) -> dict:\n",
    "    \"\"\"\n",
    "    do the lemmatization\n",
    "    \"\"\"\n",
    "    row['text'] = [token.lemma_ for token in nlp(row['text'])]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097cb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatization_train = preprocess_train.map(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09756db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatization_test = preprocess_test.map(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ede1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1]\n",
    "logprior, loglikelihood, voc = train_naive_bayes(lemmatization_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy(lemmatization_test, logprior, loglikelihood, classes, voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d242173b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
