{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed67f02b",
   "metadata": {},
   "source": [
    "# FastText (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a6e2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "from datasets import load_dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9b8a5",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "## Load and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "532d3aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/maxenceoden/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355c44feab7f4253af228ac3f5584742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/maxenceoden/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-d8e5ee367e34a906.arrow\n",
      "Loading cached processed dataset at /home/maxenceoden/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-bc11a628dc776776.arrow\n",
      "Loading cached processed dataset at /home/maxenceoden/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-39e499381803f536.arrow\n",
      "Loading cached split indices for dataset at /home/maxenceoden/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-5f37fd0866e4f89f.arrow and /home/maxenceoden/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-dd5732a0e6ac784c.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20000, 2), (5000, 2), (25000, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "# Split dataset\n",
    "train_dataset = dataset[\"train\"].train_test_split(\n",
    "    stratify_by_column=\"label\", test_size=0.2, seed=42, shuffle=True\n",
    ")\n",
    "test_df = dataset[\"test\"]\n",
    "train_df = train_dataset[\"train\"]\n",
    "valid_df = train_dataset[\"test\"]\n",
    "train_df.shape, valid_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4863972",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- Lowercase\n",
    "- Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138db2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_filter = ['\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+',\n",
    "                      ',', '.', '/', ':', ';', '<', '=', '>', '?', '@',\n",
    "                      '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n",
    "\n",
    "def to_lower_case(row: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Lower text field in the row dict\n",
    "    return: updated row\n",
    "    \"\"\"\n",
    "    row['text'] = row['text'].lower()\n",
    "    return row\n",
    "\n",
    "def remove_punctuation(row: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Replace punctuation from punctuation_filter list to\n",
    "    spaces in the text field of row dict\n",
    "    return: updated row\n",
    "    \"\"\"\n",
    "    for punctuation in punctuation_filter:\n",
    "        row['text'] = row['text'].replace(punctuation, ' ')\n",
    "    row['text'] = row['text'].replace('!', ' ! ')\n",
    "    return row\n",
    "\n",
    "def preprocessing(row: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Lower text field in the row dict and replace punctuation\n",
    "    from punctuation_filter list to spaces in the text field\n",
    "    of row dict\n",
    "    return: updated row\n",
    "    \"\"\"\n",
    "    return to_lower_case(remove_punctuation(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50517e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/maxenceoden/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-bc11a628dc776776.arrow\n",
      "Loading cached processed dataset at /home/maxenceoden/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-09e237570f4ca186.arrow\n",
      "Loading cached processed dataset at /home/maxenceoden/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-7377700f087d94f7.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'in a genre by itself  this film has a limited audience and narrow appeal coupled with a subtle undertone which permeates the entire production  nevertheless  it is a remarkable piece of cinema which is as timeless as a rare work of art  capturing a time in québec rarely seen in movies  mon oncle antoine s strength lies in the depth of its characters and the richness of the settings  duplessis  québec  parochial and feudal  is brilliantly cast as the backdrop which could not possibly be achieved by anyone other than a pure laine québecois  br    br   it would be far too easy to resort to stereotypes  clichés and single-minded myopic statements in this story  yet the director chose to skip the forced imagery and instead  focused on the essence of life in rural québec of the time  that makes this film exceptional in its authenticity while not being pretentious in its presentation  if only more contemporary cinematic endeavors would do the same  the viewing public might not be forced to choose between the over-hyped hollywood pablum that passes for  must see  viewing  br    br   mon oncle antoine is - in every sense of the word - unforgettable  it will leave a lasting impression on anyone who has ever lived in - or visited - québec  a classic                                                 br    br   follow-up  10 may 2008 br    br   after reviewing some of the comments  it s worth noting mon oncle antoine is not - and probably wasn t meant to serve as standard hollywood american cinema for mass market sales  a coming of age story  yes  but far more than simple memoirs of adolescence in 1940 s québec  viewers who re looking for sheer entertainment at the expense of complex development of the characters will be sorely disappointed  go watch action adventure romance comedies to be amused  watch mon oncle antoine to be drawn into a seldom seen  but absolutely remarkable society that has been overlooked and ignored for far too long  br    br   the grapes of wrath is hardly an edge-of-the-seat thriller  yet the story and characters are what makes this american classic an enduring film  mon oncle antoine is in the same genre '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = test_df.map(preprocessing).shuffle()\n",
    "Xvalid = valid_df.map(preprocessing).shuffle()\n",
    "Xtrain = train_df.map(preprocessing).shuffle()\n",
    "Xtest['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c21d09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1512a8",
   "metadata": {},
   "source": [
    "## Create fasttext input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5cd2040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(file_name: str, dataset) -> None:\n",
    "    with open(file_name, 'w') as f:\n",
    "        #index_list = np.arange(len(dataset))\n",
    "        #np.random.shuffle(index_list)\n",
    "        for sample in dataset:\n",
    "            f.write(f\"__label__{sample['label']} {sample['text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb3c771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset(\"valid.txt\", Xvalid)\n",
    "gen_dataset(\"train.txt\", Xtrain)\n",
    "gen_dataset(\"test.txt\", Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb17fbaa",
   "metadata": {},
   "source": [
    "# Train a FastText classifier with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e39eaae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  86070\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 4976132 lr:  0.000000 avg.loss:  0.424125 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "default_model = fasttext.train_supervised('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc3bcf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 0.86912, 0.86912)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_model.test('test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b198ac",
   "metadata": {},
   "source": [
    "# Hyper parameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "feaf5656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:    9 Best score:  0.897200 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 4M words\n",
      "Number of words:  86070\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  996486 lr:  0.000000 avg.loss:  0.046579 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "hyper_model = fasttext.train_supervised(input='train.txt', autotuneValidationFile='valid.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "826c444c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 0.89576, 0.89576)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_model.test(\"test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c0e3b3",
   "metadata": {},
   "source": [
    "# Differences between the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3c8d64c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Field      |  default model   |     hyper model     |\n",
      "------------+------------------+---------------------+\n",
      " Dimension  | 100              | 92                  |\n",
      " minn       | 0                | 0                   |\n",
      " maxn       | 0                | 0                   |\n",
      " neg        | 5                | 5                   |\n",
      " wordNgrams | 1                | 2                   |\n",
      " lr         | 0.1              | 0.08499425639667486 |\n",
      " minCount   | 1                | 1                   |\n"
     ]
    }
   ],
   "source": [
    "print(f\" Field      |  default model   |     hyper model     |\")\n",
    "print(f\"------------+------------------+---------------------+\")\n",
    "print(f\" Dimension  | {default_model.get_dimension()}              | {hyper_model.get_dimension()}                  |\")\n",
    "print(f\" minn       | {default_model.minn}                | {hyper_model.minn}                   |\")\n",
    "print(f\" maxn       | {default_model.maxn}                | {hyper_model.maxn}                   |\")\n",
    "print(f\" neg        | {default_model.neg}                | {hyper_model.neg}                   |\")\n",
    "print(f\" wordNgrams | {default_model.wordNgrams}                | {hyper_model.wordNgrams}                   |\")\n",
    "print(f\" lr         | {default_model.lr}              | {hyper_model.lr} |\")\n",
    "print(f\" minCount   | {default_model.minCount}                | {hyper_model.minCount}                   |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd49d2",
   "metadata": {},
   "source": [
    "# 2 wrongly classified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8e42978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wrong_classified(model):\n",
    "    errors = []\n",
    "    for sample in Xtest:\n",
    "        if len(sample['text']) > 2000:\n",
    "            continue\n",
    "        prediction = model.predict(sample['text'])\n",
    "        if int(prediction[0][0][-1]) != sample['label']:\n",
    "            if len(errors) == 1:\n",
    "                if sample['label'] == errors[0][0]['label']:\n",
    "                    continue\n",
    "            errors.append((sample, prediction))\n",
    "            if len(errors) == 2:\n",
    "                return errors\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7fd1eded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'text': 'uzumaki succeeds as at plunging you into a bizarre surreality where uzumaki shapes haunt and curse a town  it fails at being a competent horror movie  while the film is sure to draw attention mainly to it s bizarre plot line and a few interesting visual treats  it s going to come off better as a dark comedy than a horror film  it s definitely a film you should see if your into the kind of stuff- but if your looking for a scare or even a small chill  you ll want to look elsewhere  uzumaki doesn t really have much else up it s sleeve but a great chain of odd events  br    br   a',\n",
       "   'label': 1},\n",
       "  (('__label__0',), array([0.99533099]))),\n",
       " ({'text': 'okay  this movie starts out and it  looks  like it s going to be a cute comedy about a completely obsessed soap opera fan  she has no touch with reality whatsoever outside of the soap  sort of the inverse of the main characters in  pleasantville   and runs away to los angeles to meet a fictional character  well it is a cute movie    but at the same time  it is also a dark  very violent movie about two hitmen who are out to kill betty for reasons way to complex to recount here  either plotline would have been enough on it s own  but  nurse betty  contains both stories at once  and the effect is very jarring  i didn t much enjoy it ',\n",
       "   'label': 0},\n",
       "  (('__label__1',), array([0.57720834])))]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wrong_classified(hyper_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0bff8",
   "metadata": {},
   "source": [
    "- The first comment is clasified as positive because the author was disappointed that the film is not a horror movie.\n",
    "- The second comment is clasified as negative. The author of the comment don't explicity say that he likes the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd376a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
